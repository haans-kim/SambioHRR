#!/usr/bin/env python3
import sqlite3
import sys
import time
from datetime import datetime

def convert_tag_data_batch():
    """
    1-5ì›” tag_dataë¥¼ sambio_analytics.dbì˜ master_events_tableë¡œ ë³€í™˜ (ìµœì í™”ëœ ë²„ì „)
    ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê³  ì§„í–‰ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    
    human_db_path = '/Users/hanskim/Projects/SambioHRR/sambio_human.db'
    analytics_db_path = '/Users/hanskim/Projects/SambioHRR/sambio_analytics.db'
    
    try:
        # Connect to both databases
        human_conn = sqlite3.connect(human_db_path)
        analytics_conn = sqlite3.connect(analytics_db_path)
        
        human_cursor = human_conn.cursor()
        analytics_cursor = analytics_conn.cursor()
        
        print("ğŸ“Š 1-5ì›” tag_data â†’ master_events_table ë³€í™˜ ì‹œì‘")
        
        # Check current master_events_table size
        analytics_cursor.execute("SELECT COUNT(*) FROM master_events_table")
        current_count = analytics_cursor.fetchone()[0]
        print(f"í˜„ì¬ master_events_table ë ˆì½”ë“œ ìˆ˜: {current_count:,}")
        
        # Count total records to convert (1-5ì›”ë§Œ)
        human_cursor.execute("""
            SELECT COUNT(*) FROM tag_data 
            WHERE substr(ë‚ ì§œ, 1, 7) IN ('2025-01', '2025-02', '2025-03', '2025-04', '2025-05')
        """)
        total_records = human_cursor.fetchone()[0]
        print(f"ë³€í™˜í•  1-5ì›” tag_data ë ˆì½”ë“œ ìˆ˜: {total_records:,}")
        
        if total_records == 0:
            print("âŒ ë³€í™˜í•  1-5ì›” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        # Process in smaller batches (5000 records at a time)
        batch_size = 5000
        processed = 0
        start_time = time.time()
        
        # Get data in batches
        offset = 0
        while offset < total_records:
            batch_start_time = time.time()
            
            print(f"\nğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬: {offset:,} ~ {min(offset + batch_size, total_records):,}")
            
            # Fetch batch
            human_cursor.execute("""
                SELECT 
                    ì‚¬ë²ˆ,
                    ë‚ ì§œ,
                    ì‹œê°„,
                    ìœ„ì¹˜,
                    ì¥ë¹„ë²ˆí˜¸,
                    CASE 
                        WHEN ìœ„ì¹˜ LIKE '%ì‹ë‹¹%' OR ìœ„ì¹˜ LIKE '%ì¹´í˜%' THEN 'meal'
                        WHEN ìœ„ì¹˜ LIKE '%íšŒì˜%' OR ìœ„ì¹˜ LIKE '%ë¯¸íŒ…%' THEN 'meeting' 
                        WHEN ìœ„ì¹˜ LIKE '%íœ´ê²Œ%' OR ìœ„ì¹˜ LIKE '%ë¼ìš´ì§€%' THEN 'rest'
                        WHEN ìœ„ì¹˜ LIKE '%í™”ì¥ì‹¤%' OR ìœ„ì¹˜ LIKE '%ë³µë„%' THEN 'movement'
                        ELSE 'work'
                    END as activity_type
                FROM tag_data 
                WHERE substr(ë‚ ì§œ, 1, 7) IN ('2025-01', '2025-02', '2025-03', '2025-04', '2025-05')
                ORDER BY ì‚¬ë²ˆ, ë‚ ì§œ, ì‹œê°„
                LIMIT ? OFFSET ?
            """, (batch_size, offset))
            
            batch_records = human_cursor.fetchall()
            
            if not batch_records:
                break
                
            # Convert and insert batch
            insert_data = []
            for record in batch_records:
                ì‚¬ë²ˆ, ë‚ ì§œ, ì‹œê°„, ìœ„ì¹˜, ì¥ë¹„ë²ˆí˜¸, activity_type = record
                
                # Create datetime
                try:
                    dt = datetime.strptime(f"{ë‚ ì§œ} {ì‹œê°„}", "%Y-%m-%d %H:%M:%S")
                    timestamp = dt.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    continue  # Skip invalid datetime
                    
                insert_data.append((
                    ì‚¬ë²ˆ,           # employee_id
                    timestamp,      # timestamp  
                    activity_type,  # activity_type
                    ìœ„ì¹˜ or '',     # location_name
                    ì¥ë¹„ë²ˆí˜¸ or '', # equipment_id
                    1.0,           # confidence_score (ê¸°ë³¸ê°’)
                    'tag_data',    # data_source
                    None,          # additional_info
                    timestamp      # created_at
                ))
            
            # Insert batch
            if insert_data:
                analytics_cursor.executemany("""
                    INSERT OR IGNORE INTO master_events_table 
                    (employee_id, timestamp, activity_type, location_name, equipment_id, 
                     confidence_score, data_source, additional_info, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, insert_data)
                
                analytics_conn.commit()
                
            processed += len(batch_records)
            offset += batch_size
            
            # Progress info
            batch_time = time.time() - batch_start_time
            total_time = time.time() - start_time
            progress = (processed / total_records) * 100
            avg_time_per_record = total_time / processed if processed > 0 else 0
            eta_seconds = avg_time_per_record * (total_records - processed)
            
            print(f"âœ… ë°°ì¹˜ ì™„ë£Œ: {len(insert_data):,}ê°œ ë³€í™˜/ì‚½ì… ({batch_time:.1f}ì´ˆ)")
            print(f"ğŸ“Š ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({processed:,}/{total_records:,})")
            print(f"â±ï¸  ì˜ˆìƒ ì™„ë£Œ ì‹œê°„: {eta_seconds/60:.1f}ë¶„ í›„")
            
            # Prevent timeout by yielding
            time.sleep(0.1)
        
        # Final verification
        analytics_cursor.execute("SELECT COUNT(*) FROM master_events_table")
        final_count = analytics_cursor.fetchone()[0]
        added_records = final_count - current_count
        
        total_time = time.time() - start_time
        
        print(f"\nğŸ¯ ë³€í™˜ ì™„ë£Œ!")
        print(f"ğŸ“ˆ ì¶”ê°€ëœ ë ˆì½”ë“œ: {added_records:,}")
        print(f"ğŸ“Š ìµœì¢… master_events_table í¬ê¸°: {final_count:,}")
        print(f"â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")
        print(f"ğŸš€ ì²˜ë¦¬ ì†ë„: {processed/(total_time):.0f} records/sec")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        try:
            human_conn.close()
            analytics_conn.close()
        except:
            pass

if __name__ == "__main__":
    convert_tag_data_batch()